{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-27T16:16:04.192212Z",
     "start_time": "2025-04-27T16:16:04.165678Z"
    }
   },
   "source": [
    "# train.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from prepare_data import create_dataloaders\n",
    "\n",
    "# ----------------------\n",
    "# CONFIGURATION\n",
    "# ----------------------\n",
    "NUM_CLASSES = 29  # Update if needed\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 20\n",
    "LEARNING_RATE = 1e-4\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# STEP 1: Load Data\n",
    "# ----------------------\n",
    "train_loader, val_loader, test_loader = create_dataloaders(batch_size=BATCH_SIZE)\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets ready: 1212 train, 335 val, 205 test samples.\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T16:16:06.900958Z",
     "start_time": "2025-04-27T16:16:06.714136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ----------------------\n",
    "# STEP 2: Load Model\n",
    "# ----------------------\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "\n"
   ],
   "id": "354c9a745d57c1d3",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T16:16:09.555005Z",
     "start_time": "2025-04-27T16:16:09.452652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Replace the final layer\n",
    "model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "model = model.to(DEVICE)\n",
    "model\n"
   ],
   "id": "fbb3456ae664a865",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=29, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T16:16:10.936511Z",
     "start_time": "2025-04-27T16:16:10.932173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ----------------------\n",
    "# STEP 3: Define Loss and Optimizer\n",
    "# ----------------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n"
   ],
   "id": "466f5ea7da479fba",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T16:16:14.434298Z",
     "start_time": "2025-04-27T16:16:14.428728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ----------------------\n",
    "# STEP 4: Training Loop\n",
    "# ----------------------\n",
    "def train(model, train_loader, val_loader, criterion, optimizer, num_epochs=NUM_EPOCHS):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        train_loss = running_loss / total\n",
    "        train_acc = 100. * correct / total\n",
    "\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "# ----------------------\n",
    "# STEP 5: Evaluation Function\n",
    "# ----------------------\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    loss = running_loss / total\n",
    "    acc = 100. * correct / total\n",
    "    return loss, acc\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "78170d5a723eeba1",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T16:32:53.231374Z",
     "start_time": "2025-04-27T16:16:27.254937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ----------------------\n",
    "# STEP 6: Start Training\n",
    "# ----------------------\n",
    "if __name__ == '__main__':\n",
    "    train(model, train_loader, val_loader, criterion, optimizer, num_epochs=15)\n",
    "\n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), 'resnet50_marburglens.pth')\n",
    "    print(\"Training complete and model saved!\")"
   ],
   "id": "467f80048c54a08b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15] | Train Loss: 2.4510 | Train Acc: 38.86% | Val Loss: 1.1011 | Val Acc: 72.54%\n",
      "Epoch [2/15] | Train Loss: 1.0296 | Train Acc: 76.32% | Val Loss: 0.4922 | Val Acc: 91.04%\n",
      "Epoch [3/15] | Train Loss: 0.5207 | Train Acc: 89.11% | Val Loss: 0.2220 | Val Acc: 95.22%\n",
      "Epoch [4/15] | Train Loss: 0.3584 | Train Acc: 91.42% | Val Loss: 0.1828 | Val Acc: 95.52%\n",
      "Epoch [5/15] | Train Loss: 0.2711 | Train Acc: 94.22% | Val Loss: 0.0897 | Val Acc: 98.51%\n",
      "Epoch [6/15] | Train Loss: 0.2010 | Train Acc: 95.87% | Val Loss: 0.0926 | Val Acc: 98.21%\n",
      "Epoch [7/15] | Train Loss: 0.1887 | Train Acc: 95.71% | Val Loss: 0.0951 | Val Acc: 98.21%\n",
      "Epoch [8/15] | Train Loss: 0.1788 | Train Acc: 95.46% | Val Loss: 0.1044 | Val Acc: 97.91%\n",
      "Epoch [9/15] | Train Loss: 0.1598 | Train Acc: 96.12% | Val Loss: 0.0717 | Val Acc: 98.51%\n",
      "Epoch [10/15] | Train Loss: 0.1640 | Train Acc: 96.12% | Val Loss: 0.0626 | Val Acc: 98.51%\n",
      "Epoch [11/15] | Train Loss: 0.1161 | Train Acc: 96.95% | Val Loss: 0.0613 | Val Acc: 98.81%\n",
      "Epoch [12/15] | Train Loss: 0.1504 | Train Acc: 95.87% | Val Loss: 0.0602 | Val Acc: 99.10%\n",
      "Epoch [13/15] | Train Loss: 0.1642 | Train Acc: 96.12% | Val Loss: 0.0815 | Val Acc: 98.21%\n",
      "Epoch [14/15] | Train Loss: 0.1224 | Train Acc: 97.03% | Val Loss: 0.0554 | Val Acc: 99.10%\n",
      "Epoch [15/15] | Train Loss: 0.1302 | Train Acc: 97.19% | Val Loss: 0.0776 | Val Acc: 98.21%\n",
      "Training complete and model saved!\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T16:35:45.746274Z",
     "start_time": "2025-04-27T16:35:28.168499Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from prepare_data import create_dataloaders\n",
    "train_loader, _, _ = create_dataloaders(batch_size=32)\n",
    "\n",
    "# Get the class names\n",
    "classes = train_loader.dataset.classes\n",
    "print(classes)\n",
    "\n",
    "# See one batch\n",
    "inputs, labels = next(iter(train_loader))\n",
    "print(labels)  # Tensor of integers like tensor([3, 5, 2, 7, ...])\n",
    "print([classes[label] for label in labels])  # Converts back to building names\n"
   ],
   "id": "da7417675bb6c1c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets ready: 1212 train, 335 val, 205 test samples.\n",
      "['Bahnhofstraße 7', 'Barfüßstraße 1', 'Biegenstraße 11', 'Biegenstraße 12', 'Biegenstraße 14', 'Biegenstraße 9', 'Deutschhausstraße 1', 'Deutschhausstraße 10, Deutches Haus, Fachbereich Geographie', 'Deutschhausstraße 12', 'Deutschhausstraße 17', 'Deutschhausstraße 17A', 'Deutschhausstraße 17B', 'Deutschhausstraße 3', 'Ketzerbach 11', 'Ketzerbach 63', 'Landgraf-Philipp-Straße 4', 'Marbacher Weg 6', 'Mineralogisches Museum', 'Pilgrimstein 2', 'Renthof 5', 'Renthof 6', 'Robert-Koch-Straße 4', 'Robert-Koch-Straße 6', 'Roter-Graben-10', 'Schulstraße 12', 'Universitätsstraße 24', 'Universitätsstraße 25', 'Universitätsstraße 6', 'Universitätsstraße 7']\n",
      "tensor([15, 16, 28,  7, 14, 21,  5,  7, 15, 15,  7, 24, 26, 21, 25,  4, 12, 18,\n",
      "         2, 25,  7,  4, 22,  8, 22, 16,  4, 27, 18,  3, 20, 28])\n",
      "['Landgraf-Philipp-Straße 4', 'Marbacher Weg 6', 'Universitätsstraße 7', 'Deutschhausstraße 10, Deutches Haus, Fachbereich Geographie', 'Ketzerbach 63', 'Robert-Koch-Straße 4', 'Biegenstraße 9', 'Deutschhausstraße 10, Deutches Haus, Fachbereich Geographie', 'Landgraf-Philipp-Straße 4', 'Landgraf-Philipp-Straße 4', 'Deutschhausstraße 10, Deutches Haus, Fachbereich Geographie', 'Schulstraße 12', 'Universitätsstraße 25', 'Robert-Koch-Straße 4', 'Universitätsstraße 24', 'Biegenstraße 14', 'Deutschhausstraße 3', 'Pilgrimstein 2', 'Biegenstraße 11', 'Universitätsstraße 24', 'Deutschhausstraße 10, Deutches Haus, Fachbereich Geographie', 'Biegenstraße 14', 'Robert-Koch-Straße 6', 'Deutschhausstraße 12', 'Robert-Koch-Straße 6', 'Marbacher Weg 6', 'Biegenstraße 14', 'Universitätsstraße 6', 'Pilgrimstein 2', 'Biegenstraße 12', 'Renthof 6', 'Universitätsstraße 7']\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T16:38:33.387877Z",
     "start_time": "2025-04-27T16:38:32.894840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# Load your trained model\n",
    "model = models.resnet50(weights=None)\n",
    "model.fc = nn.Linear(model.fc.in_features, 29)  # Adjust for 29 classes\n",
    "model.load_state_dict(torch.load('resnet50_marburglens.pth'))\n",
    "model.eval()\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Prepare the same transform as validation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load and preprocess your image\n",
    "img_path = 'test_images/myphoto.jpg'  # <- your image path\n",
    "image = Image.open(img_path).convert('RGB')\n",
    "input_tensor = transform(image).unsqueeze(0).to(DEVICE)  # Add batch dimension\n",
    "\n",
    "# Make prediction\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_tensor)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "# Map prediction to building name\n",
    "from prepare_data import create_dataloaders\n",
    "train_loader, _, _ = create_dataloaders(batch_size=32)\n",
    "class_names = train_loader.dataset.classes\n",
    "\n",
    "predicted_class = class_names[preds.item()]\n",
    "print(f'Predicted Building: {predicted_class}')\n"
   ],
   "id": "8f19f246b6185306",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sOrOush\\AppData\\Local\\Temp\\ipykernel_95352\\3207310441.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('resnet50_marburglens.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets ready: 1212 train, 335 val, 205 test samples.\n",
      "Predicted Building: Universitätsstraße 25\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7a559ff815803f7a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
