{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5588df89-f393-4afb-95b4-4df603115258",
   "metadata": {
    "id": "5588df89-f393-4afb-95b4-4df603115258",
    "outputId": "01f10485-da08-4985-8c03-3464c4549cce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading images...\n",
      "Loaded 100 images\n",
      "2. Training...\n",
      "Epoch [10/1000], Avg Loss: 37619.8031, Avg Recon Loss: 37616.0484, Avg KL Loss: 375.4036\n",
      "Epoch [20/1000], Avg Loss: 28992.0812, Avg Recon Loss: 28982.5747, Avg KL Loss: 950.6728\n",
      "Epoch [30/1000], Avg Loss: 24842.4440, Avg Recon Loss: 24821.7477, Avg KL Loss: 2069.6466\n",
      "Epoch [40/1000], Avg Loss: 21714.9682, Avg Recon Loss: 21670.1356, Avg KL Loss: 4483.2349\n",
      "Epoch [50/1000], Avg Loss: 18911.2373, Avg Recon Loss: 18846.3570, Avg KL Loss: 6488.0650\n",
      "Epoch [60/1000], Avg Loss: 17201.5645, Avg Recon Loss: 17123.7127, Avg KL Loss: 7785.1626\n",
      "Epoch [70/1000], Avg Loss: 15284.3010, Avg Recon Loss: 15192.6783, Avg KL Loss: 9162.2698\n",
      "Epoch [80/1000], Avg Loss: 14147.1512, Avg Recon Loss: 14052.5613, Avg KL Loss: 9458.9909\n",
      "Epoch [90/1000], Avg Loss: 13396.8391, Avg Recon Loss: 13299.1347, Avg KL Loss: 9770.4260\n",
      "Epoch [100/1000], Avg Loss: 12303.8392, Avg Recon Loss: 12198.5276, Avg KL Loss: 10531.1629\n",
      "Epoch [110/1000], Avg Loss: 11676.8538, Avg Recon Loss: 11569.9073, Avg KL Loss: 10694.6352\n",
      "Epoch [120/1000], Avg Loss: 11653.8350, Avg Recon Loss: 11547.9944, Avg KL Loss: 10584.0539\n",
      "Epoch [130/1000], Avg Loss: 10606.5825, Avg Recon Loss: 10529.6146, Avg KL Loss: 7696.7855\n",
      "Epoch [140/1000], Avg Loss: 10022.4762, Avg Recon Loss: 9929.9136, Avg KL Loss: 9256.2531\n",
      "Epoch [150/1000], Avg Loss: 9759.5556, Avg Recon Loss: 9662.5237, Avg KL Loss: 9703.2070\n",
      "Epoch [160/1000], Avg Loss: 9138.4608, Avg Recon Loss: 9038.3176, Avg KL Loss: 10014.3277\n",
      "Epoch [170/1000], Avg Loss: 9102.1837, Avg Recon Loss: 9003.5594, Avg KL Loss: 9862.4386\n",
      "Epoch [180/1000], Avg Loss: 8640.4497, Avg Recon Loss: 8538.4731, Avg KL Loss: 10197.6714\n",
      "Epoch [190/1000], Avg Loss: 8215.7174, Avg Recon Loss: 8112.3538, Avg KL Loss: 10336.3607\n",
      "Epoch [200/1000], Avg Loss: 7964.1877, Avg Recon Loss: 7860.6552, Avg KL Loss: 10353.2361\n",
      "Epoch [210/1000], Avg Loss: 7916.1906, Avg Recon Loss: 7813.7433, Avg KL Loss: 10244.7199\n",
      "Epoch [220/1000], Avg Loss: 7507.2770, Avg Recon Loss: 7405.1687, Avg KL Loss: 10210.8404\n",
      "Epoch [230/1000], Avg Loss: 7353.4386, Avg Recon Loss: 7251.5387, Avg KL Loss: 10189.9927\n",
      "Epoch [240/1000], Avg Loss: 7266.0486, Avg Recon Loss: 7170.0275, Avg KL Loss: 9602.0941\n",
      "Epoch [250/1000], Avg Loss: 7239.0804, Avg Recon Loss: 7141.3873, Avg KL Loss: 9769.3095\n",
      "Epoch [260/1000], Avg Loss: 6712.7487, Avg Recon Loss: 6611.4979, Avg KL Loss: 10125.0823\n",
      "Epoch [270/1000], Avg Loss: 6924.2497, Avg Recon Loss: 6823.5648, Avg KL Loss: 10068.4937\n",
      "Epoch [280/1000], Avg Loss: 6317.2382, Avg Recon Loss: 6214.0857, Avg KL Loss: 10315.2484\n",
      "Epoch [290/1000], Avg Loss: 6334.7405, Avg Recon Loss: 6232.8619, Avg KL Loss: 10187.8619\n",
      "Epoch [300/1000], Avg Loss: 6095.5594, Avg Recon Loss: 5997.6581, Avg KL Loss: 9790.1169\n",
      "Epoch [310/1000], Avg Loss: 5916.3198, Avg Recon Loss: 5816.4492, Avg KL Loss: 9987.0552\n",
      "Epoch [320/1000], Avg Loss: 6308.3467, Avg Recon Loss: 6217.7493, Avg KL Loss: 9059.7409\n",
      "Epoch [330/1000], Avg Loss: 5737.2209, Avg Recon Loss: 5642.6077, Avg KL Loss: 9461.3273\n",
      "Epoch [340/1000], Avg Loss: 5609.1911, Avg Recon Loss: 5511.8613, Avg KL Loss: 9732.9713\n",
      "Epoch [350/1000], Avg Loss: 5514.5152, Avg Recon Loss: 5418.4002, Avg KL Loss: 9611.5000\n",
      "Epoch [360/1000], Avg Loss: 5670.5084, Avg Recon Loss: 5575.0867, Avg KL Loss: 9542.1660\n",
      "Epoch [370/1000], Avg Loss: 5294.4254, Avg Recon Loss: 5198.8813, Avg KL Loss: 9554.4021\n",
      "Epoch [380/1000], Avg Loss: 5122.5033, Avg Recon Loss: 5028.0377, Avg KL Loss: 9446.5591\n",
      "Epoch [390/1000], Avg Loss: 4939.0749, Avg Recon Loss: 4843.7488, Avg KL Loss: 9532.6047\n",
      "Epoch [400/1000], Avg Loss: 5417.1505, Avg Recon Loss: 5325.3035, Avg KL Loss: 9184.6882\n",
      "Epoch [410/1000], Avg Loss: 4806.9947, Avg Recon Loss: 4714.6188, Avg KL Loss: 9237.6077\n",
      "Epoch [420/1000], Avg Loss: 4578.6523, Avg Recon Loss: 4486.4519, Avg KL Loss: 9220.0431\n",
      "Epoch [430/1000], Avg Loss: 4607.1374, Avg Recon Loss: 4515.7555, Avg KL Loss: 9138.1966\n",
      "Epoch [440/1000], Avg Loss: 4778.2932, Avg Recon Loss: 4690.3479, Avg KL Loss: 8794.5133\n",
      "Epoch [450/1000], Avg Loss: 4766.9133, Avg Recon Loss: 4680.3337, Avg KL Loss: 8657.9529\n",
      "Epoch [460/1000], Avg Loss: 4314.0342, Avg Recon Loss: 4225.8500, Avg KL Loss: 8818.4109\n",
      "Epoch [470/1000], Avg Loss: 4360.8824, Avg Recon Loss: 4274.2007, Avg KL Loss: 8668.1699\n",
      "Epoch [480/1000], Avg Loss: 4191.0462, Avg Recon Loss: 4104.0329, Avg KL Loss: 8701.3416\n",
      "Epoch [490/1000], Avg Loss: 4221.1665, Avg Recon Loss: 4135.1695, Avg KL Loss: 8599.7075\n",
      "Epoch [500/1000], Avg Loss: 4655.1507, Avg Recon Loss: 4570.2588, Avg KL Loss: 8489.1888\n",
      "Epoch [510/1000], Avg Loss: 3954.8514, Avg Recon Loss: 3870.7383, Avg KL Loss: 8411.3061\n",
      "Epoch [520/1000], Avg Loss: 4005.8270, Avg Recon Loss: 3921.5772, Avg KL Loss: 8424.9879\n",
      "Epoch [530/1000], Avg Loss: 3925.6632, Avg Recon Loss: 3843.2736, Avg KL Loss: 8238.9590\n",
      "Epoch [540/1000], Avg Loss: 3813.9096, Avg Recon Loss: 3732.6623, Avg KL Loss: 8124.7344\n",
      "Epoch [550/1000], Avg Loss: 3688.2070, Avg Recon Loss: 3607.8019, Avg KL Loss: 8040.5064\n",
      "Epoch [560/1000], Avg Loss: 3592.1270, Avg Recon Loss: 3511.9527, Avg KL Loss: 8017.4261\n",
      "Epoch [570/1000], Avg Loss: 3778.1551, Avg Recon Loss: 3697.1479, Avg KL Loss: 8100.7099\n",
      "Epoch [580/1000], Avg Loss: 4213.3236, Avg Recon Loss: 4135.3910, Avg KL Loss: 7793.2591\n",
      "Epoch [590/1000], Avg Loss: 3567.7098, Avg Recon Loss: 3491.3804, Avg KL Loss: 7632.9473\n",
      "Epoch [600/1000], Avg Loss: 3364.7190, Avg Recon Loss: 3288.6802, Avg KL Loss: 7603.8857\n",
      "Epoch [610/1000], Avg Loss: 3343.0059, Avg Recon Loss: 3267.1865, Avg KL Loss: 7581.9474\n",
      "Epoch [620/1000], Avg Loss: 3602.5129, Avg Recon Loss: 3530.9443, Avg KL Loss: 7156.8632\n",
      "Epoch [630/1000], Avg Loss: 3337.1555, Avg Recon Loss: 3265.2294, Avg KL Loss: 7192.6051\n",
      "Epoch [640/1000], Avg Loss: 3244.1966, Avg Recon Loss: 3170.4641, Avg KL Loss: 7373.2552\n",
      "Epoch [650/1000], Avg Loss: 3385.3202, Avg Recon Loss: 3313.0420, Avg KL Loss: 7227.8207\n",
      "Epoch [660/1000], Avg Loss: 4014.6687, Avg Recon Loss: 3945.1476, Avg KL Loss: 6952.1148\n",
      "Epoch [670/1000], Avg Loss: 3163.8936, Avg Recon Loss: 3094.3351, Avg KL Loss: 6955.8506\n",
      "Epoch [680/1000], Avg Loss: 3012.3369, Avg Recon Loss: 2942.2479, Avg KL Loss: 7008.9108\n",
      "Epoch [690/1000], Avg Loss: 2996.9952, Avg Recon Loss: 2927.0609, Avg KL Loss: 6993.4375\n",
      "Epoch [700/1000], Avg Loss: 3022.0254, Avg Recon Loss: 2952.2259, Avg KL Loss: 6979.9462\n",
      "Epoch [710/1000], Avg Loss: 3233.6569, Avg Recon Loss: 3166.2348, Avg KL Loss: 6742.2137\n",
      "Epoch [720/1000], Avg Loss: 2927.3605, Avg Recon Loss: 2860.2936, Avg KL Loss: 6706.6828\n",
      "Epoch [730/1000], Avg Loss: 2999.8740, Avg Recon Loss: 2934.0156, Avg KL Loss: 6585.8372\n",
      "Epoch [740/1000], Avg Loss: 3335.4502, Avg Recon Loss: 3271.3503, Avg KL Loss: 6409.9874\n",
      "Epoch [750/1000], Avg Loss: 2833.7670, Avg Recon Loss: 2769.4182, Avg KL Loss: 6434.8738\n",
      "Epoch [760/1000], Avg Loss: 2745.5704, Avg Recon Loss: 2680.6400, Avg KL Loss: 6493.0420\n",
      "Epoch [770/1000], Avg Loss: 2814.4847, Avg Recon Loss: 2750.1780, Avg KL Loss: 6430.6665\n",
      "Epoch [780/1000], Avg Loss: 2736.7374, Avg Recon Loss: 2672.8167, Avg KL Loss: 6392.0751\n",
      "Epoch [790/1000], Avg Loss: 2753.9307, Avg Recon Loss: 2691.0795, Avg KL Loss: 6285.1099\n",
      "Epoch [800/1000], Avg Loss: 3135.7094, Avg Recon Loss: 3073.6174, Avg KL Loss: 6209.2015\n",
      "Epoch [810/1000], Avg Loss: 2851.3324, Avg Recon Loss: 2790.3751, Avg KL Loss: 6095.7259\n",
      "Epoch [820/1000], Avg Loss: 2655.5036, Avg Recon Loss: 2595.4815, Avg KL Loss: 6002.2099\n",
      "Epoch [830/1000], Avg Loss: 2579.0587, Avg Recon Loss: 2518.8901, Avg KL Loss: 6016.8618\n",
      "Epoch [840/1000], Avg Loss: 2744.4799, Avg Recon Loss: 2684.0806, Avg KL Loss: 6039.9377\n",
      "Epoch [850/1000], Avg Loss: 2693.2087, Avg Recon Loss: 2635.2385, Avg KL Loss: 5797.0187\n",
      "Epoch [860/1000], Avg Loss: 2527.3460, Avg Recon Loss: 2470.3191, Avg KL Loss: 5702.6930\n",
      "Epoch [870/1000], Avg Loss: 2451.5574, Avg Recon Loss: 2394.3712, Avg KL Loss: 5718.6250\n",
      "Epoch [880/1000], Avg Loss: 2590.4006, Avg Recon Loss: 2534.2809, Avg KL Loss: 5611.9736\n",
      "Epoch [890/1000], Avg Loss: 2495.3086, Avg Recon Loss: 2440.0068, Avg KL Loss: 5530.1800\n",
      "Epoch [900/1000], Avg Loss: 2583.8380, Avg Recon Loss: 2530.3869, Avg KL Loss: 5345.1122\n",
      "Epoch [910/1000], Avg Loss: 2573.5309, Avg Recon Loss: 2519.6251, Avg KL Loss: 5390.5855\n",
      "Epoch [920/1000], Avg Loss: 2374.7574, Avg Recon Loss: 2320.5251, Avg KL Loss: 5423.2299\n",
      "Epoch [930/1000], Avg Loss: 2306.5783, Avg Recon Loss: 2252.0182, Avg KL Loss: 5456.0157\n",
      "Epoch [940/1000], Avg Loss: 2325.0096, Avg Recon Loss: 2271.0192, Avg KL Loss: 5399.0391\n",
      "Epoch [950/1000], Avg Loss: 2655.1241, Avg Recon Loss: 2602.7417, Avg KL Loss: 5238.2436\n",
      "Epoch [960/1000], Avg Loss: 2444.9836, Avg Recon Loss: 2393.6261, Avg KL Loss: 5135.7428\n",
      "Epoch [970/1000], Avg Loss: 2265.4581, Avg Recon Loss: 2212.8632, Avg KL Loss: 5259.4831\n",
      "Epoch [980/1000], Avg Loss: 2207.9201, Avg Recon Loss: 2155.7367, Avg KL Loss: 5218.3484\n",
      "Epoch [990/1000], Avg Loss: 2212.3383, Avg Recon Loss: 2159.9753, Avg KL Loss: 5236.3089\n",
      "Epoch [1000/1000], Avg Loss: 2403.4884, Avg Recon Loss: 2353.7380, Avg KL Loss: 4975.0457\n",
      "3. Generating and saving reconstructions...\n",
      "Saved original image 0 to vae_output_highres\\original_0.png\n",
      "Saved reconstructed image 0 to vae_output_highres\\reconstructed_0.png\n",
      "Saved original image 1 to vae_output_highres\\original_1.png\n",
      "Saved reconstructed image 1 to vae_output_highres\\reconstructed_1.png\n",
      "Saved original image 2 to vae_output_highres\\original_2.png\n",
      "Saved reconstructed image 2 to vae_output_highres\\reconstructed_2.png\n",
      "Saved original image 3 to vae_output_highres\\original_3.png\n",
      "Saved reconstructed image 3 to vae_output_highres\\reconstructed_3.png\n",
      "Saved original image 4 to vae_output_highres\\original_4.png\n",
      "Saved reconstructed image 4 to vae_output_highres\\reconstructed_4.png\n",
      "Saved original image 5 to vae_output_highres\\original_5.png\n",
      "Saved reconstructed image 5 to vae_output_highres\\reconstructed_5.png\n",
      "Saved original image 6 to vae_output_highres\\original_6.png\n",
      "Saved reconstructed image 6 to vae_output_highres\\reconstructed_6.png\n",
      "Saved original image 7 to vae_output_highres\\original_7.png\n",
      "Saved reconstructed image 7 to vae_output_highres\\reconstructed_7.png\n",
      "Saved original image 8 to vae_output_highres\\original_8.png\n",
      "Saved reconstructed image 8 to vae_output_highres\\reconstructed_8.png\n",
      "Saved original image 9 to vae_output_highres\\original_9.png\n",
      "Saved reconstructed image 9 to vae_output_highres\\reconstructed_9.png\n",
      "Saved original image 10 to vae_output_highres\\original_10.png\n",
      "Saved reconstructed image 10 to vae_output_highres\\reconstructed_10.png\n",
      "Saved original image 11 to vae_output_highres\\original_11.png\n",
      "Saved reconstructed image 11 to vae_output_highres\\reconstructed_11.png\n",
      "Saved original image 12 to vae_output_highres\\original_12.png\n",
      "Saved reconstructed image 12 to vae_output_highres\\reconstructed_12.png\n",
      "Saved original image 13 to vae_output_highres\\original_13.png\n",
      "Saved reconstructed image 13 to vae_output_highres\\reconstructed_13.png\n",
      "Saved original image 14 to vae_output_highres\\original_14.png\n",
      "Saved reconstructed image 14 to vae_output_highres\\reconstructed_14.png\n",
      "Saved original image 15 to vae_output_highres\\original_15.png\n",
      "Saved reconstructed image 15 to vae_output_highres\\reconstructed_15.png\n",
      "Saved original image 16 to vae_output_highres\\original_16.png\n",
      "Saved reconstructed image 16 to vae_output_highres\\reconstructed_16.png\n",
      "Saved original image 17 to vae_output_highres\\original_17.png\n",
      "Saved reconstructed image 17 to vae_output_highres\\reconstructed_17.png\n",
      "Saved original image 18 to vae_output_highres\\original_18.png\n",
      "Saved reconstructed image 18 to vae_output_highres\\reconstructed_18.png\n",
      "Saved original image 19 to vae_output_highres\\original_19.png\n",
      "Saved reconstructed image 19 to vae_output_highres\\reconstructed_19.png\n",
      "4. Process completed!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "class VDVAE(nn.Module):\n",
    "    def __init__(self, latent_dim=256):\n",
    "        super(VDVAE, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 4, stride=2, padding=1),     # 128x128\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(32, 64, 4, stride=2, padding=1),    # 64x64\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),   # 32x32\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1),  # 16x16\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(256, 512, 4, stride=2, padding=1),  # 8x8\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(512, 512, 4, stride=2, padding=1),  # 4x4\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        # Bottleneck\n",
    "        self.fc_mu = nn.Linear(512 * 4 * 4, latent_dim)\n",
    "        self.fc_var = nn.Linear(512 * 4 * 4, latent_dim)\n",
    "\n",
    "        # Decoder input\n",
    "        self.decoder_input = nn.Linear(latent_dim, 512 * 4 * 4)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 512, 4, stride=2, padding=1),  # 8x8\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ConvTranspose2d(512, 256, 4, stride=2, padding=1),  # 16x16\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),  # 32x32\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),   # 64x64\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),    # 128x128\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ConvTranspose2d(32, 3, 4, stride=2, padding=1),     # 256x256\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        mu = self.fc_mu(x)\n",
    "        log_var = self.fc_var(x)\n",
    "        return mu, log_var\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        x = self.decoder_input(z)\n",
    "        x = x.view(x.size(0), 512, 4, 4)\n",
    "        return self.decoder(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        return self.decode(z), mu, log_var\n",
    "\n",
    "try:\n",
    "    # Setup\n",
    "    folder_path = r\"C:\\Users\\sOrOush\\SoroushProjects\\00_scratchpad\\images\\processed_images\"\n",
    "    files = [f for f in os.listdir(folder_path)\n",
    "             if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    # Parameters\n",
    "    batch_size = 16\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    # Transform for 256x256 images\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    print(\"1. Loading images...\")\n",
    "    images = []\n",
    "    for file in files:\n",
    "        img_path = os.path.join(folder_path, file)\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img_tensor = transform(img)\n",
    "        images.append(img_tensor)\n",
    "\n",
    "    all_images = torch.stack(images)\n",
    "    dataset = TensorDataset(all_images)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    print(f\"Loaded {len(all_images)} images\")\n",
    "\n",
    "    # Create and train model\n",
    "    model = VDVAE().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    print(\"2. Training...\")\n",
    "    num_epochs = 1000\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        total_recon_loss = 0\n",
    "        total_kl_loss = 0\n",
    "\n",
    "        for batch_idx, (data,) in enumerate(dataloader):\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            recon_batch, mu, log_var = model(data)\n",
    "\n",
    "            # Loss calculation\n",
    "            recon_loss = F.mse_loss(recon_batch, data, reduction='sum')\n",
    "            kl_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "            loss = recon_loss + 0.01 * kl_loss\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_recon_loss += recon_loss.item()\n",
    "            total_kl_loss += kl_loss.item()\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            avg_loss = total_loss / len(dataloader.dataset)\n",
    "            avg_recon = total_recon_loss / len(dataloader.dataset)\n",
    "            avg_kl = total_kl_loss / len(dataloader.dataset)\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "                  f'Avg Loss: {avg_loss:.4f}, '\n",
    "                  f'Avg Recon Loss: {avg_recon:.4f}, '\n",
    "                  f'Avg KL Loss: {avg_kl:.4f}')\n",
    "\n",
    "    print(\"3. Generating and saving reconstructions...\")\n",
    "    model.eval()\n",
    "    output_dir = 'vae_output_highres'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Iterate through the dataloader until at least 20 pairs are saved\n",
    "        pair_count = 0\n",
    "        for data_batch in dataloader:\n",
    "            test_batch = data_batch[0].to(device)\n",
    "            reconstructions = model(test_batch)[0]\n",
    "\n",
    "            batch_size = test_batch.size(0)\n",
    "            for i in range(batch_size):\n",
    "                try:\n",
    "                    # Save original\n",
    "                    orig_img = test_batch[i].cpu().numpy().transpose(1, 2, 0)\n",
    "                    orig_img = ((orig_img + 1) * 127.5).astype(np.uint8)\n",
    "                    orig_pil = Image.fromarray(orig_img)\n",
    "                    orig_path = os.path.join(output_dir, f'original_{pair_count}.png')\n",
    "                    orig_pil.save(orig_path)\n",
    "                    print(f\"Saved original image {pair_count} to {orig_path}\")\n",
    "\n",
    "                    # Save reconstruction\n",
    "                    recon_img = reconstructions[i].cpu().numpy().transpose(1, 2, 0)\n",
    "                    recon_img = ((recon_img + 1) * 127.5).astype(np.uint8)\n",
    "                    recon_pil = Image.fromarray(recon_img)\n",
    "                    recon_path = os.path.join(output_dir, f'reconstructed_{pair_count}.png')\n",
    "                    recon_pil.save(recon_path)\n",
    "                    print(f\"Saved reconstructed image {pair_count} to {recon_path}\")\n",
    "\n",
    "                    pair_count += 1\n",
    "\n",
    "                    # Stop after saving 20 pairs\n",
    "                    if pair_count >= 20:\n",
    "                        break\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error saving image {pair_count}: {e}\")\n",
    "\n",
    "            if pair_count >= 20:\n",
    "                break\n",
    "\n",
    "    print(\"4. Process completed!\")\n",
    "\n",
    "    # print(\"3. Generating and saving reconstructions...\")\n",
    "    # model.eval()\n",
    "    # output_dir = 'vae_output_highres'\n",
    "    # os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # with torch.no_grad():\n",
    "    #     # Get first batch\n",
    "    #     test_batch = next(iter(dataloader))[0].to(device)\n",
    "    #     reconstructions = model(test_batch)[0]\n",
    "\n",
    "    #     # Save first 5 pairs\n",
    "    #     for i in range(5):\n",
    "    #         try:\n",
    "    #             # Save original\n",
    "    #             orig_img = test_batch[i].cpu().numpy().transpose(1, 2, 0)\n",
    "    #             orig_img = ((orig_img + 1) * 127.5).astype(np.uint8)\n",
    "    #             orig_pil = Image.fromarray(orig_img)\n",
    "    #             orig_path = os.path.join(output_dir, f'original_{i}.png')\n",
    "    #             orig_pil.save(orig_path)\n",
    "    #             print(f\"Saved original image {i} to {orig_path}\")\n",
    "\n",
    "    #             # Save reconstruction\n",
    "    #             recon_img = reconstructions[i].cpu().numpy().transpose(1, 2, 0)\n",
    "    #             recon_img = ((recon_img + 1) * 127.5).astype(np.uint8)\n",
    "    #             recon_pil = Image.fromarray(recon_img)\n",
    "    #             recon_path = os.path.join(output_dir, f'reconstructed_{i}.png')\n",
    "    #             recon_pil.save(recon_path)\n",
    "    #             print(f\"Saved reconstructed image {i} to {recon_path}\")\n",
    "\n",
    "    #         except Exception as e:\n",
    "    #             print(f\"Error saving image {i}: {e}\")\n",
    "\n",
    "    # print(\"4. Process completed!\")\n",
    "\n",
    "    # Clean up\n",
    "    del model, reconstructions, test_batch\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "id": "4d853a96-6440-4f06-9a40-758c13692590",
   "metadata": {
    "id": "4d853a96-6440-4f06-9a40-758c13692590",
    "ExecuteTime": {
     "end_time": "2025-05-03T13:55:21.500185Z",
     "start_time": "2025-05-03T13:54:51.313928Z"
    }
   },
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# VDVAE Definition\n",
    "class VDVAE(nn.Module):\n",
    "    def __init__(self, latent_dim=256):\n",
    "        super(VDVAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(32, 64, 4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(256, 512, 4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(512, 512, 4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(512 * 4 * 4, latent_dim)\n",
    "        self.fc_var = nn.Linear(512 * 4 * 4, latent_dim)\n",
    "        self.decoder_input = nn.Linear(latent_dim, 512 * 4 * 4)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 512, 4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ConvTranspose2d(512, 256, 4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ConvTranspose2d(32, 3, 4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc_mu(x), self.fc_var(x)\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        x = self.decoder_input(z)\n",
    "        x = x.view(x.size(0), 512, 4, 4)\n",
    "        return self.decoder(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        return self.decode(z), mu, log_var\n",
    "\n",
    "# Load images from folder\n",
    "def load_images(folder_path, image_size=(256, 256)):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,) * 3, (0.5,) * 3)\n",
    "    ])\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            path = os.path.join(folder_path, filename)\n",
    "            img = Image.open(path).convert('RGB')\n",
    "            images.append(transform(img))\n",
    "    return torch.stack(images)\n",
    "\n",
    "# Save image tensor as PNG\n",
    "def save_image(tensor, path):\n",
    "    img = tensor.cpu().numpy().transpose(1, 2, 0)\n",
    "    img = ((img + 1) * 127.5).astype(np.uint8)\n",
    "    Image.fromarray(img).save(path)\n",
    "\n",
    "# Train function\n",
    "def train(model, dataloader, optimizer, device, epochs=100):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss, total_recon, total_kl = 0, 0, 0\n",
    "        for data, in dataloader:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            recon, mu, log_var = model(data)\n",
    "            recon_loss = F.mse_loss(recon, data, reduction='sum')\n",
    "            kl_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "            loss = recon_loss + 0.01 * kl_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            total_recon += recon_loss.item()\n",
    "            total_kl += kl_loss.item()\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            n = len(dataloader.dataset)\n",
    "            print(f\"Epoch {epoch+1}/{epochs} | \"\n",
    "                  f\"Loss: {total_loss/n:.2f} | \"\n",
    "                  f\"Recon: {total_recon/n:.2f} | \"\n",
    "                  f\"KL: {total_kl/n:.2f}\")\n",
    "\n",
    "# Main\n",
    "def main():\n",
    "    folder_path = r\"C:\\Users\\sOrOush\\SoroushProjects\\00_scratchpad\\images\\processed_images\"\n",
    "    output_dir = \"vae_output_highres\"\n",
    "    model_path = \"vae_minimal.pth\"\n",
    "    batch_size = 16\n",
    "    epochs = 2\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Loading images...\")\n",
    "    images = load_images(folder_path)\n",
    "    dataloader = DataLoader(TensorDataset(images), batch_size=batch_size, shuffle=True)\n",
    "    print(f\"{len(images)} images loaded.\")\n",
    "\n",
    "    model = VDVAE().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    train(model, dataloader, optimizer, device, epochs=epochs)\n",
    "\n",
    "    print(f\"Saving model to {model_path}...\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    print(f\"Saving reconstructions to '{output_dir}'...\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pair_count = 0\n",
    "        for data, in dataloader:\n",
    "            data = data.to(device)\n",
    "            recon = model(data)[0]\n",
    "            for i in range(data.size(0)):\n",
    "                save_image(data[i], os.path.join(output_dir, f\"original_{pair_count}.png\"))\n",
    "                save_image(recon[i], os.path.join(output_dir, f\"reconstructed_{pair_count}.png\"))\n",
    "                pair_count += 1\n",
    "                if pair_count >= 20:\n",
    "                    break\n",
    "            if pair_count >= 20:\n",
    "                break\n",
    "    print(\"Done!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(\"An error occurred:\")\n",
    "        traceback.print_exc()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images...\n",
      "6827 images loaded.\n",
      "Starting training...\n",
      "Saving model to vae_minimal.pth...\n",
      "Saving reconstructions to 'vae_output_highres'...\n",
      "Done!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T13:48:47.522091Z",
     "start_time": "2025-05-03T13:48:41.248879Z"
    }
   },
   "cell_type": "code",
   "source": "pip install torchviz",
   "id": "8275fe754011144a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchviz\n",
      "  Downloading torchviz-0.0.3-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\soroush\\appdata\\roaming\\python\\python312\\site-packages (from torchviz) (2.5.1+cu118)\n",
      "Collecting graphviz (from torchviz)\n",
      "  Downloading graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\soroush\\.conda\\envs\\linearity_question\\lib\\site-packages (from torch->torchviz) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\soroush\\.conda\\envs\\linearity_question\\lib\\site-packages (from torch->torchviz) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\soroush\\.conda\\envs\\linearity_question\\lib\\site-packages (from torch->torchviz) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\soroush\\.conda\\envs\\linearity_question\\lib\\site-packages (from torch->torchviz) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\soroush\\.conda\\envs\\linearity_question\\lib\\site-packages (from torch->torchviz) (2024.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\soroush\\.conda\\envs\\linearity_question\\lib\\site-packages (from torch->torchviz) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\soroush\\appdata\\roaming\\python\\python312\\site-packages (from torch->torchviz) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\soroush\\.conda\\envs\\linearity_question\\lib\\site-packages (from sympy==1.13.1->torch->torchviz) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\soroush\\.conda\\envs\\linearity_question\\lib\\site-packages (from jinja2->torch->torchviz) (2.1.3)\n",
      "Downloading torchviz-0.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
      "Installing collected packages: graphviz, torchviz\n",
      "Successfully installed graphviz-0.20.3 torchviz-0.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T13:55:36.394829Z",
     "start_time": "2025-05-03T13:55:35.671478Z"
    }
   },
   "cell_type": "code",
   "source": [
    " from torchviz import make_dot\n",
    "\n",
    "model = VDVAE()\n",
    "dummy_input = torch.randn(1, 3, 256, 256)\n",
    "output, mu, logvar = model(dummy_input)\n",
    "dot = make_dot(output, params=dict(model.named_parameters()))\n",
    "dot.format = 'png'\n",
    "dot.render('vae_architecture')\n"
   ],
   "id": "8a5cee7a8855bf49",
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[1;32m~\\.conda\\envs\\linearity_question\\Lib\\site-packages\\graphviz\\backend\\execute.py:78\u001B[0m, in \u001B[0;36mrun_check\u001B[1;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001B[0m\n\u001B[0;32m     77\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 78\u001B[0m         proc \u001B[38;5;241m=\u001B[39m subprocess\u001B[38;5;241m.\u001B[39mrun(cmd, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     79\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\.conda\\envs\\linearity_question\\Lib\\subprocess.py:548\u001B[0m, in \u001B[0;36mrun\u001B[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001B[0m\n\u001B[0;32m    546\u001B[0m     kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstderr\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m PIPE\n\u001B[1;32m--> 548\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m Popen(\u001B[38;5;241m*\u001B[39mpopenargs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;28;01mas\u001B[39;00m process:\n\u001B[0;32m    549\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\.conda\\envs\\linearity_question\\Lib\\subprocess.py:1026\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001B[0m\n\u001B[0;32m   1023\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstderr \u001B[38;5;241m=\u001B[39m io\u001B[38;5;241m.\u001B[39mTextIOWrapper(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstderr,\n\u001B[0;32m   1024\u001B[0m                     encoding\u001B[38;5;241m=\u001B[39mencoding, errors\u001B[38;5;241m=\u001B[39merrors)\n\u001B[1;32m-> 1026\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_execute_child(args, executable, preexec_fn, close_fds,\n\u001B[0;32m   1027\u001B[0m                         pass_fds, cwd, env,\n\u001B[0;32m   1028\u001B[0m                         startupinfo, creationflags, shell,\n\u001B[0;32m   1029\u001B[0m                         p2cread, p2cwrite,\n\u001B[0;32m   1030\u001B[0m                         c2pread, c2pwrite,\n\u001B[0;32m   1031\u001B[0m                         errread, errwrite,\n\u001B[0;32m   1032\u001B[0m                         restore_signals,\n\u001B[0;32m   1033\u001B[0m                         gid, gids, uid, umask,\n\u001B[0;32m   1034\u001B[0m                         start_new_session, process_group)\n\u001B[0;32m   1035\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[0;32m   1036\u001B[0m     \u001B[38;5;66;03m# Cleanup if the child failed starting.\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\linearity_question\\Lib\\subprocess.py:1538\u001B[0m, in \u001B[0;36mPopen._execute_child\u001B[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001B[0m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1538\u001B[0m     hp, ht, pid, tid \u001B[38;5;241m=\u001B[39m _winapi\u001B[38;5;241m.\u001B[39mCreateProcess(executable, args,\n\u001B[0;32m   1539\u001B[0m                              \u001B[38;5;66;03m# no special security\u001B[39;00m\n\u001B[0;32m   1540\u001B[0m                              \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1541\u001B[0m                              \u001B[38;5;28mint\u001B[39m(\u001B[38;5;129;01mnot\u001B[39;00m close_fds),\n\u001B[0;32m   1542\u001B[0m                              creationflags,\n\u001B[0;32m   1543\u001B[0m                              env,\n\u001B[0;32m   1544\u001B[0m                              cwd,\n\u001B[0;32m   1545\u001B[0m                              startupinfo)\n\u001B[0;32m   1546\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m   1547\u001B[0m     \u001B[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001B[39;00m\n\u001B[0;32m   1548\u001B[0m     \u001B[38;5;66;03m# handles that only the child should have open.  You need\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;66;03m# pipe will not close when the child process exits and the\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m     \u001B[38;5;66;03m# ReadFile will hang.\u001B[39;00m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 2] The system cannot find the file specified",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mExecutableNotFound\u001B[0m                        Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m dot \u001B[38;5;241m=\u001B[39m make_dot(output, params\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mdict\u001B[39m(model\u001B[38;5;241m.\u001B[39mnamed_parameters()))\n\u001B[0;32m      7\u001B[0m dot\u001B[38;5;241m.\u001B[39mformat \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpng\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m----> 8\u001B[0m dot\u001B[38;5;241m.\u001B[39mrender(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvae_architecture\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\linearity_question\\Lib\\site-packages\\graphviz\\_tools.py:171\u001B[0m, in \u001B[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    162\u001B[0m     wanted \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvalue\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    163\u001B[0m                        \u001B[38;5;28;01mfor\u001B[39;00m name, value \u001B[38;5;129;01min\u001B[39;00m deprecated\u001B[38;5;241m.\u001B[39mitems())\n\u001B[0;32m    164\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThe signature of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m will be reduced\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    165\u001B[0m                   \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msupported_number\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m positional args\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    166\u001B[0m                   \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlist\u001B[39m(supported)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: pass \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mwanted\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    167\u001B[0m                   \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m as keyword arg(s)\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m    168\u001B[0m                   stacklevel\u001B[38;5;241m=\u001B[39mstacklevel,\n\u001B[0;32m    169\u001B[0m                   category\u001B[38;5;241m=\u001B[39mcategory)\n\u001B[1;32m--> 171\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\linearity_question\\Lib\\site-packages\\graphviz\\rendering.py:122\u001B[0m, in \u001B[0;36mRender.render\u001B[1;34m(self, filename, directory, view, cleanup, format, renderer, formatter, neato_no_op, quiet, quiet_view, outfile, engine, raise_if_result_exists, overwrite_source)\u001B[0m\n\u001B[0;32m    118\u001B[0m filepath \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave(filename, directory\u001B[38;5;241m=\u001B[39mdirectory, skip_existing\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    120\u001B[0m args\u001B[38;5;241m.\u001B[39mappend(filepath)\n\u001B[1;32m--> 122\u001B[0m rendered \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_render(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    124\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cleanup:\n\u001B[0;32m    125\u001B[0m     log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdelete \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m'\u001B[39m, filepath)\n",
      "File \u001B[1;32m~\\.conda\\envs\\linearity_question\\Lib\\site-packages\\graphviz\\_tools.py:171\u001B[0m, in \u001B[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    162\u001B[0m     wanted \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvalue\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    163\u001B[0m                        \u001B[38;5;28;01mfor\u001B[39;00m name, value \u001B[38;5;129;01min\u001B[39;00m deprecated\u001B[38;5;241m.\u001B[39mitems())\n\u001B[0;32m    164\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThe signature of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m will be reduced\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    165\u001B[0m                   \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msupported_number\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m positional args\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    166\u001B[0m                   \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlist\u001B[39m(supported)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: pass \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mwanted\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    167\u001B[0m                   \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m as keyword arg(s)\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m    168\u001B[0m                   stacklevel\u001B[38;5;241m=\u001B[39mstacklevel,\n\u001B[0;32m    169\u001B[0m                   category\u001B[38;5;241m=\u001B[39mcategory)\n\u001B[1;32m--> 171\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\linearity_question\\Lib\\site-packages\\graphviz\\backend\\rendering.py:326\u001B[0m, in \u001B[0;36mrender\u001B[1;34m(engine, format, filepath, renderer, formatter, neato_no_op, quiet, outfile, raise_if_result_exists, overwrite_filepath)\u001B[0m\n\u001B[0;32m    322\u001B[0m cmd \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m args\n\u001B[0;32m    324\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m filepath \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwork around pytype false alarm\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m--> 326\u001B[0m execute\u001B[38;5;241m.\u001B[39mrun_check(cmd,\n\u001B[0;32m    327\u001B[0m                   cwd\u001B[38;5;241m=\u001B[39mfilepath\u001B[38;5;241m.\u001B[39mparent \u001B[38;5;28;01mif\u001B[39;00m filepath\u001B[38;5;241m.\u001B[39mparent\u001B[38;5;241m.\u001B[39mparts \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    328\u001B[0m                   quiet\u001B[38;5;241m=\u001B[39mquiet,\n\u001B[0;32m    329\u001B[0m                   capture_output\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    331\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m os\u001B[38;5;241m.\u001B[39mfspath(outfile)\n",
      "File \u001B[1;32m~\\.conda\\envs\\linearity_question\\Lib\\site-packages\\graphviz\\backend\\execute.py:81\u001B[0m, in \u001B[0;36mrun_check\u001B[1;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001B[0m\n\u001B[0;32m     79\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     80\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m e\u001B[38;5;241m.\u001B[39merrno \u001B[38;5;241m==\u001B[39m errno\u001B[38;5;241m.\u001B[39mENOENT:\n\u001B[1;32m---> 81\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ExecutableNotFound(cmd) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[0;32m     82\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[0;32m     84\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m quiet \u001B[38;5;129;01mand\u001B[39;00m proc\u001B[38;5;241m.\u001B[39mstderr:\n",
      "\u001B[1;31mExecutableNotFound\u001B[0m: failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T13:59:42.428054Z",
     "start_time": "2025-05-03T13:59:42.381789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import graphviz\n",
    "print(graphviz.backend.viewing._viewers['windows'])\n"
   ],
   "id": "b16317272f9905a",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'graphviz.backend.viewing' has no attribute '_viewers'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mgraphviz\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28mprint\u001B[39m(graphviz\u001B[38;5;241m.\u001B[39mbackend\u001B[38;5;241m.\u001B[39mviewing\u001B[38;5;241m.\u001B[39m_viewers[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwindows\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'graphviz.backend.viewing' has no attribute '_viewers'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T14:09:11.082130Z",
     "start_time": "2025-05-03T14:09:11.078460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# pick GPU if available, else CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "id": "e6c0743aa54ae967",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T14:09:14.558533Z",
     "start_time": "2025-05-03T14:09:14.360166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "# ... after youve built & moved your model to device:\n",
    "model = VDVAE().to(device)\n",
    "model.eval()\n",
    "\n",
    "# create a dummy input the same size as your training images:\n",
    "dummy = torch.randn(1, 3, 256, 256).to(device)\n",
    "\n",
    "# forward-pass through the network:\n",
    "with torch.no_grad():\n",
    "    recon, mu, log_var = model(dummy)\n",
    "\n",
    "# build the graph; here we visualize the reconstruction branch:\n",
    "dot = make_dot(recon, params=dict(model.named_parameters()),\n",
    "                show_attrs=False,    # set to True to inspect saved tensors\n",
    "                show_saved=False)    # set to True to see backward nodes too\n",
    "\n",
    "# choose output format and render\n",
    "dot.format = 'png'\n",
    "dot.render('vdvae_graph')\n"
   ],
   "id": "f1d9100c9e76d4e6",
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[1;32m~\\.conda\\envs\\linearity_question\\Lib\\site-packages\\graphviz\\backend\\execute.py:78\u001B[0m, in \u001B[0;36mrun_check\u001B[1;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001B[0m\n\u001B[0;32m     77\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 78\u001B[0m         proc \u001B[38;5;241m=\u001B[39m subprocess\u001B[38;5;241m.\u001B[39mrun(cmd, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     79\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\.conda\\envs\\linearity_question\\Lib\\subprocess.py:548\u001B[0m, in \u001B[0;36mrun\u001B[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001B[0m\n\u001B[0;32m    546\u001B[0m     kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstderr\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m PIPE\n\u001B[1;32m--> 548\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m Popen(\u001B[38;5;241m*\u001B[39mpopenargs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;28;01mas\u001B[39;00m process:\n\u001B[0;32m    549\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\.conda\\envs\\linearity_question\\Lib\\subprocess.py:1026\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001B[0m\n\u001B[0;32m   1023\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstderr \u001B[38;5;241m=\u001B[39m io\u001B[38;5;241m.\u001B[39mTextIOWrapper(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstderr,\n\u001B[0;32m   1024\u001B[0m                     encoding\u001B[38;5;241m=\u001B[39mencoding, errors\u001B[38;5;241m=\u001B[39merrors)\n\u001B[1;32m-> 1026\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_execute_child(args, executable, preexec_fn, close_fds,\n\u001B[0;32m   1027\u001B[0m                         pass_fds, cwd, env,\n\u001B[0;32m   1028\u001B[0m                         startupinfo, creationflags, shell,\n\u001B[0;32m   1029\u001B[0m                         p2cread, p2cwrite,\n\u001B[0;32m   1030\u001B[0m                         c2pread, c2pwrite,\n\u001B[0;32m   1031\u001B[0m                         errread, errwrite,\n\u001B[0;32m   1032\u001B[0m                         restore_signals,\n\u001B[0;32m   1033\u001B[0m                         gid, gids, uid, umask,\n\u001B[0;32m   1034\u001B[0m                         start_new_session, process_group)\n\u001B[0;32m   1035\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[0;32m   1036\u001B[0m     \u001B[38;5;66;03m# Cleanup if the child failed starting.\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\linearity_question\\Lib\\subprocess.py:1538\u001B[0m, in \u001B[0;36mPopen._execute_child\u001B[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001B[0m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1538\u001B[0m     hp, ht, pid, tid \u001B[38;5;241m=\u001B[39m _winapi\u001B[38;5;241m.\u001B[39mCreateProcess(executable, args,\n\u001B[0;32m   1539\u001B[0m                              \u001B[38;5;66;03m# no special security\u001B[39;00m\n\u001B[0;32m   1540\u001B[0m                              \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1541\u001B[0m                              \u001B[38;5;28mint\u001B[39m(\u001B[38;5;129;01mnot\u001B[39;00m close_fds),\n\u001B[0;32m   1542\u001B[0m                              creationflags,\n\u001B[0;32m   1543\u001B[0m                              env,\n\u001B[0;32m   1544\u001B[0m                              cwd,\n\u001B[0;32m   1545\u001B[0m                              startupinfo)\n\u001B[0;32m   1546\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m   1547\u001B[0m     \u001B[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001B[39;00m\n\u001B[0;32m   1548\u001B[0m     \u001B[38;5;66;03m# handles that only the child should have open.  You need\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;66;03m# pipe will not close when the child process exits and the\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m     \u001B[38;5;66;03m# ReadFile will hang.\u001B[39;00m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 2] The system cannot find the file specified",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mExecutableNotFound\u001B[0m                        Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 21\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# choose output format and render\u001B[39;00m\n\u001B[0;32m     20\u001B[0m dot\u001B[38;5;241m.\u001B[39mformat \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpng\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m---> 21\u001B[0m dot\u001B[38;5;241m.\u001B[39mrender(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvdvae_graph\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\linearity_question\\Lib\\site-packages\\graphviz\\_tools.py:171\u001B[0m, in \u001B[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    162\u001B[0m     wanted \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvalue\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    163\u001B[0m                        \u001B[38;5;28;01mfor\u001B[39;00m name, value \u001B[38;5;129;01min\u001B[39;00m deprecated\u001B[38;5;241m.\u001B[39mitems())\n\u001B[0;32m    164\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThe signature of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m will be reduced\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    165\u001B[0m                   \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msupported_number\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m positional args\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    166\u001B[0m                   \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlist\u001B[39m(supported)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: pass \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mwanted\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    167\u001B[0m                   \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m as keyword arg(s)\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m    168\u001B[0m                   stacklevel\u001B[38;5;241m=\u001B[39mstacklevel,\n\u001B[0;32m    169\u001B[0m                   category\u001B[38;5;241m=\u001B[39mcategory)\n\u001B[1;32m--> 171\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\linearity_question\\Lib\\site-packages\\graphviz\\rendering.py:122\u001B[0m, in \u001B[0;36mRender.render\u001B[1;34m(self, filename, directory, view, cleanup, format, renderer, formatter, neato_no_op, quiet, quiet_view, outfile, engine, raise_if_result_exists, overwrite_source)\u001B[0m\n\u001B[0;32m    118\u001B[0m filepath \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave(filename, directory\u001B[38;5;241m=\u001B[39mdirectory, skip_existing\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    120\u001B[0m args\u001B[38;5;241m.\u001B[39mappend(filepath)\n\u001B[1;32m--> 122\u001B[0m rendered \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_render(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    124\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cleanup:\n\u001B[0;32m    125\u001B[0m     log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdelete \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m'\u001B[39m, filepath)\n",
      "File \u001B[1;32m~\\.conda\\envs\\linearity_question\\Lib\\site-packages\\graphviz\\_tools.py:171\u001B[0m, in \u001B[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    162\u001B[0m     wanted \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvalue\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    163\u001B[0m                        \u001B[38;5;28;01mfor\u001B[39;00m name, value \u001B[38;5;129;01min\u001B[39;00m deprecated\u001B[38;5;241m.\u001B[39mitems())\n\u001B[0;32m    164\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThe signature of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m will be reduced\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    165\u001B[0m                   \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msupported_number\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m positional args\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    166\u001B[0m                   \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlist\u001B[39m(supported)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: pass \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mwanted\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    167\u001B[0m                   \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m as keyword arg(s)\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m    168\u001B[0m                   stacklevel\u001B[38;5;241m=\u001B[39mstacklevel,\n\u001B[0;32m    169\u001B[0m                   category\u001B[38;5;241m=\u001B[39mcategory)\n\u001B[1;32m--> 171\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\linearity_question\\Lib\\site-packages\\graphviz\\backend\\rendering.py:326\u001B[0m, in \u001B[0;36mrender\u001B[1;34m(engine, format, filepath, renderer, formatter, neato_no_op, quiet, outfile, raise_if_result_exists, overwrite_filepath)\u001B[0m\n\u001B[0;32m    322\u001B[0m cmd \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m args\n\u001B[0;32m    324\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m filepath \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwork around pytype false alarm\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m--> 326\u001B[0m execute\u001B[38;5;241m.\u001B[39mrun_check(cmd,\n\u001B[0;32m    327\u001B[0m                   cwd\u001B[38;5;241m=\u001B[39mfilepath\u001B[38;5;241m.\u001B[39mparent \u001B[38;5;28;01mif\u001B[39;00m filepath\u001B[38;5;241m.\u001B[39mparent\u001B[38;5;241m.\u001B[39mparts \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    328\u001B[0m                   quiet\u001B[38;5;241m=\u001B[39mquiet,\n\u001B[0;32m    329\u001B[0m                   capture_output\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    331\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m os\u001B[38;5;241m.\u001B[39mfspath(outfile)\n",
      "File \u001B[1;32m~\\.conda\\envs\\linearity_question\\Lib\\site-packages\\graphviz\\backend\\execute.py:81\u001B[0m, in \u001B[0;36mrun_check\u001B[1;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001B[0m\n\u001B[0;32m     79\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     80\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m e\u001B[38;5;241m.\u001B[39merrno \u001B[38;5;241m==\u001B[39m errno\u001B[38;5;241m.\u001B[39mENOENT:\n\u001B[1;32m---> 81\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ExecutableNotFound(cmd) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[0;32m     82\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[0;32m     84\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m quiet \u001B[38;5;129;01mand\u001B[39;00m proc\u001B[38;5;241m.\u001B[39mstderr:\n",
      "\u001B[1;31mExecutableNotFound\u001B[0m: failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f694fdbc5d9b1308"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
